{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2023-08-30T09:52:58.138283-06:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.10.12\n",
      "IPython version      : 8.12.2\n",
      "\n",
      "Compiler    : GCC 11.2.0\n",
      "OS          : Linux\n",
      "Release     : 6.2.0-27-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 6\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_inexistente1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col_outliers</th>\n",
       "      <th>col_outliers2</th>\n",
       "      <th>col_categorica</th>\n",
       "      <th>col_ordinal</th>\n",
       "      <th>col_texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.232832</td>\n",
       "      <td>-50</td>\n",
       "      <td>0.771666</td>\n",
       "      <td>ratón</td>\n",
       "      <td>muy bien</td>\n",
       "      <td>Tenía en su casa una ama que pasaba de los cua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.906147</td>\n",
       "      <td>-5</td>\n",
       "      <td>1.068558</td>\n",
       "      <td>elefante</td>\n",
       "      <td>regular</td>\n",
       "      <td>El resto della concluían sayo de velarte, calz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.626750</td>\n",
       "      <td>-32</td>\n",
       "      <td>0.846396</td>\n",
       "      <td>ratón</td>\n",
       "      <td>muy mal</td>\n",
       "      <td>El resto della concluían sayo de velarte, calz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.816738</td>\n",
       "      <td>-84</td>\n",
       "      <td>0.637381</td>\n",
       "      <td>gato</td>\n",
       "      <td>mal</td>\n",
       "      <td>Una olla de algo más vaca que carnero, salpicó...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.571131</td>\n",
       "      <td>65</td>\n",
       "      <td>4.540614</td>\n",
       "      <td>gato</td>\n",
       "      <td>bien</td>\n",
       "      <td>Tenía en su casa una ama que pasaba de los cua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_inexistente1  col2      col3  col_outliers  col_outliers2  \\\n",
       "0              59.0  52.0  2.232832           -50       0.771666   \n",
       "1              31.0  74.0  0.906147            -5       1.068558   \n",
       "2              81.0  28.0  0.626750           -32       0.846396   \n",
       "3              34.0  16.0  0.816738           -84       0.637381   \n",
       "4              32.0  28.0  0.571131            65       4.540614   \n",
       "\n",
       "  col_categorica col_ordinal  \\\n",
       "0          ratón    muy bien   \n",
       "1       elefante     regular   \n",
       "2          ratón     muy mal   \n",
       "3           gato         mal   \n",
       "4           gato        bien   \n",
       "\n",
       "                                           col_texto  \n",
       "0  Tenía en su casa una ama que pasaba de los cua...  \n",
       "1  El resto della concluían sayo de velarte, calz...  \n",
       "2  El resto della concluían sayo de velarte, calz...  \n",
       "3  Una olla de algo más vaca que carnero, salpicó...  \n",
       "4  Tenía en su casa una ama que pasaba de los cua...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = pd.read_csv(\"data/datos_procesamiento.csv\")\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col_inexistente1    float64\n",
       "col2                float64\n",
       "col3                float64\n",
       "col_outliers          int64\n",
       "col_outliers2       float64\n",
       "col_categorica       object\n",
       "col_ordinal          object\n",
       "col_texto            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables Numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputación de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col_inexistente1    float64\n",
       "col2                float64\n",
       "col3                float64\n",
       "col_outliers          int64\n",
       "col_outliers2       float64\n",
       "col_categorica       object\n",
       "col_ordinal          object\n",
       "col_texto            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['col_inexistente1', 'col2', 'col3', 'col_outliers', 'col_outliers2'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_df = datos.select_dtypes([int, float])\n",
    "var_numericas_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_df[var_numericas_df.isnull().any(axis=1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_inexistente1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col_outliers</th>\n",
       "      <th>col_outliers2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.270999</td>\n",
       "      <td>62</td>\n",
       "      <td>1.067230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.394209</td>\n",
       "      <td>98</td>\n",
       "      <td>4.145716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.437365</td>\n",
       "      <td>59</td>\n",
       "      <td>20.549474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.324893</td>\n",
       "      <td>98</td>\n",
       "      <td>0.761684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>3.664671</td>\n",
       "      <td>-48</td>\n",
       "      <td>3.154153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    col_inexistente1  col2      col3  col_outliers  col_outliers2\n",
       "9                NaN  53.0  2.270999            62       1.067230\n",
       "10               NaN  99.0  1.394209            98       4.145716\n",
       "16               NaN  50.0  0.437365            59      20.549474\n",
       "17               NaN  73.0  0.324893            98       0.761684\n",
       "23               NaN  85.0  3.664671           -48       3.154153"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_df[var_numericas_df.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from sklearn.impute import SimpleImputer\n",
    "imputador = SimpleImputer(strategy=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_numericas_imputadas = imputador.fit_transform(var_numericas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59.        ,  52.        ,   2.23283208, -50.        ,\n",
       "          0.77166646],\n",
       "       [ 31.        ,  74.        ,   0.90614714,  -5.        ,\n",
       "          1.06855838],\n",
       "       [ 81.        ,  28.        ,   0.62675042, -32.        ,\n",
       "          0.84639576],\n",
       "       ...,\n",
       "       [ 19.        ,  53.        ,   0.73723413,  73.        ,\n",
       "          1.34525201],\n",
       "       [ 88.        ,  94.        ,   0.76008706,  68.        ,\n",
       "          1.3692463 ],\n",
       "       [ 94.        ,  56.        ,   1.2299403 ,  61.        ,\n",
       "          0.94395714]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_inexistente1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col_outliers</th>\n",
       "      <th>col_outliers2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.232832</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>0.771666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.906147</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1.068558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.626750</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>0.846396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.816738</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>0.637381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.571131</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.540614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.618844</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.812940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.167880</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.235137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.229813</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.283176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.407978</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.298613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48.382743</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.270999</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.067230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_inexistente1  col2       col3  col_outliers  col_outliers2\n",
       "0         59.000000  52.0   2.232832         -50.0       0.771666\n",
       "1         31.000000  74.0   0.906147          -5.0       1.068558\n",
       "2         81.000000  28.0   0.626750         -32.0       0.846396\n",
       "3         34.000000  16.0   0.816738         -84.0       0.637381\n",
       "4         32.000000  28.0   0.571131          65.0       4.540614\n",
       "5         81.000000   4.0   1.618844          51.0       0.812940\n",
       "6         57.000000  31.0   0.167880          78.0       1.235137\n",
       "7         34.000000  20.0  20.229813          93.0       1.283176\n",
       "8         37.000000  96.0   2.407978          54.0       1.298613\n",
       "9         48.382743  53.0   2.270999          62.0       1.067230"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_df = pd.DataFrame(var_numericas_imputadas,\n",
    "                                                   index=var_numericas_df.index,\n",
    "                                                   columns=var_numericas_df.columns)\n",
    "\n",
    "var_numericas_imputadas_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_df[var_numericas_imputadas_df.isnull().any(axis=1)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Estandarización**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso de Estandardización es un proceso requerido por una gran cantidad de modelos en Scikit-learn. El objetivo es obtener una variable con media 0 y desviación estándar 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['col_inexistente1', 'col2', 'col3', 'col_outliers', 'col_outliers2'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col_inexistente1     48.382743\n",
       "col2                 49.660000\n",
       "col3                  1.466095\n",
       "col_outliers          4.253000\n",
       "col_outliers2       131.193340\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col_inexistente1      27.987174\n",
       "col2                  28.272668\n",
       "col3                   1.732358\n",
       "col_outliers          78.145901\n",
       "col_outliers2       3401.164776\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_df.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello el transformador mas sencillo en sklearn es [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "escalador = preprocessing.StandardScaler()\n",
    "var_numericas_imputadas_escalado_standard = escalador.fit_transform(var_numericas_imputadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 48.38274336,  49.66      ,   1.46609489,   4.253     ,\n",
       "       131.19333968])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "escalador.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.86197757e-17,  1.26121336e-16, -3.90798505e-17,  3.55271368e-18,\n",
       "       -3.55271368e-18])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_standard.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_standard.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39921733,  0.08280686,  0.44281884, -0.69460006, -0.03836537])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_standard[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para aquellos casos en los que los datos tengan muchos valores extremos, es posible que estandarizar usando la media y la desviacion estandar no funcione bien en el modelo. Para esos casos es mejor usar unos estimadores mas robustos (menos sensibles a outliers) y emplear un [RobustScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler) que funciona substrayendo la mediana y escalando mediante el rango intercuartil (IQR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "escalador_robusto = preprocessing.RobustScaler()\n",
    "var_numericas_imputadas_escalado_robusto = escalador_robusto.fit_transform(\n",
    "                                                        var_numericas_imputadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.81916720e-17, -2.85106383e-02,  4.01958704e-01,  3.04018692e-02,\n",
       "        7.03130782e+01])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_robusto.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.33218559e-01, 6.01245275e-01, 1.38651621e+00, 7.29970260e-01,\n",
       "       1.83690817e+03])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_robusto.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Escalado a un rango especifico**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay casos en los que en vez de estandardizar queremos escalar los datos a un rango (generalmente [-1,1] o [0,1]). Para ello podemos usar [MinMaxScaler](scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler) que hace escalado minmax (obviamente) o [MaxAbscaler](scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbscaler) que simplemente divide cada valor de una variable por su valor máximo (y por tanto convierte el valor maximo a 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-100.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107357.85777352"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "escalador_minmax = preprocessing.MinMaxScaler()\n",
    "var_numericas_imputadas_escalado_minmax = escalador_minmax.fit_transform(var_numericas_imputadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_minmax.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_minmax.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "escalador_maxabs = preprocessing.MaxAbsScaler()\n",
    "var_numericas_imputadas_escalado_maxabs = escalador_maxabs.fit_transform(var_numericas_imputadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_maxabs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1122334455667789"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_maxabs.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Hay casos en los que lo que se necesita es tener observaciones con norma unitaria (norma L2 o euclidiana). Para esos casos, podemos usar [Normalizer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = preprocessing.Normalizer()\n",
    "var_numericas_imputadas_normal = normalizador.fit_transform(var_numericas_imputadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que tener en cuenta que el objetivo del Normalizer es normalizar casos, no variables (o sea que funciona por filas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.38557802,  0.92041204,  0.01127066, -0.06219   ,  0.01329073])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_normal[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(var_numericas_imputadas_normal[1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Otras transformaciones**\n",
    "\n",
    "Para aquellos casos en los que queremos aplicar una función arbitraria a una variable podemos usar [FunctionTransformer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, la variable `col3` no tiene una distribución normal, sino que tiene una asimetria muy marcada (es una distribución lognormal). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(datos.col3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una práctica frecuente es aplicar el logaritmo a dichas variables para convertirlas a variables con una distribución mas normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "transformer = FunctionTransformer(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17860/983924610.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcol3_transformada\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"col3\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcol3_transformada\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol3_transformada\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol3_transformada\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkdeplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol3_transformada\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "col3_transformada = transformer.transform(datos[[\"col3\"]])\n",
    "col3_transformada = col3_transformada.reshape(col3_transformada.shape[0],)\n",
    "sns.kdeplot(col3_transformada);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Variables Categoricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos están diseñados para trabajar con variables numéricas. Esto implica que para poder entrenar los modelos con variables categóricas tenemos que convertirlas a números. Este proceso se llama *codificación (encoding)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_inexistente1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col_outliers</th>\n",
       "      <th>col_outliers2</th>\n",
       "      <th>col_categorica</th>\n",
       "      <th>col_ordinal</th>\n",
       "      <th>col_texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.232832</td>\n",
       "      <td>-50</td>\n",
       "      <td>0.771666</td>\n",
       "      <td>ratón</td>\n",
       "      <td>muy bien</td>\n",
       "      <td>Tenía en su casa una ama que pasaba de los cua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.906147</td>\n",
       "      <td>-5</td>\n",
       "      <td>1.068558</td>\n",
       "      <td>elefante</td>\n",
       "      <td>regular</td>\n",
       "      <td>El resto della concluían sayo de velarte, calz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.626750</td>\n",
       "      <td>-32</td>\n",
       "      <td>0.846396</td>\n",
       "      <td>ratón</td>\n",
       "      <td>muy mal</td>\n",
       "      <td>El resto della concluían sayo de velarte, calz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.816738</td>\n",
       "      <td>-84</td>\n",
       "      <td>0.637381</td>\n",
       "      <td>gato</td>\n",
       "      <td>mal</td>\n",
       "      <td>Una olla de algo más vaca que carnero, salpicó...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.571131</td>\n",
       "      <td>65</td>\n",
       "      <td>4.540614</td>\n",
       "      <td>gato</td>\n",
       "      <td>bien</td>\n",
       "      <td>Tenía en su casa una ama que pasaba de los cua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_inexistente1  col2      col3  col_outliers  col_outliers2  \\\n",
       "0              59.0  52.0  2.232832           -50       0.771666   \n",
       "1              31.0  74.0  0.906147            -5       1.068558   \n",
       "2              81.0  28.0  0.626750           -32       0.846396   \n",
       "3              34.0  16.0  0.816738           -84       0.637381   \n",
       "4              32.0  28.0  0.571131            65       4.540614   \n",
       "\n",
       "  col_categorica col_ordinal  \\\n",
       "0          ratón    muy bien   \n",
       "1       elefante     regular   \n",
       "2          ratón     muy mal   \n",
       "3           gato         mal   \n",
       "4           gato        bien   \n",
       "\n",
       "                                           col_texto  \n",
       "0  Tenía en su casa una ama que pasaba de los cua...  \n",
       "1  El resto della concluían sayo de velarte, calz...  \n",
       "2  El resto della concluían sayo de velarte, calz...  \n",
       "3  Una olla de algo más vaca que carnero, salpicó...  \n",
       "4  Tenía en su casa una ama que pasaba de los cua...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = pd.read_csv(\"data/datos_procesamiento.csv\")\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_categoricas = datos[['col_categorica', 'col_ordinal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_categorica</th>\n",
       "      <th>col_ordinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ratón</td>\n",
       "      <td>muy bien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elefante</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ratón</td>\n",
       "      <td>muy mal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gato</td>\n",
       "      <td>mal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gato</td>\n",
       "      <td>bien</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col_categorica col_ordinal\n",
       "0          ratón    muy bien\n",
       "1       elefante     regular\n",
       "2          ratón     muy mal\n",
       "3           gato         mal\n",
       "4           gato        bien"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_categoricas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay muchas formas de codificar variables, la más sencilla es reemplazar los elementos de dichas variables por un número. Por ejemplo, si hacemos esto con la columna `col_categorica`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codificador = preprocessing.LabelEncoder()\n",
    "label_codificador.fit(datos.col_ordinal) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bien', 'mal', 'muy bien', 'muy mal', 'regular'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codificador.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 2, 3, 0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codificador.transform(['muy bien', 'muy mal', 'muy bien', 'muy mal', 'bien'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bien', 'bien', 'mal', 'muy bien'], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codificador.inverse_transform([0, 0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de variables ordinales esto tiene sentido ya que `muy_bien>bien>regular>mal>muy mal`. Sin embargo, esto indica a los modelos de scikit-learn por ejemplo que `mal + regular = bien`. Esto se puede usar en según que casos (hay modelos que no interpretan las variables numéricas así), o para codificar las variables objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para variables categóricas (por ejemplo animales) no tiene sentido usar este tipo de encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 3, 1, 1, 2, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codificador_categorico = preprocessing.LabelEncoder()\n",
    "label_codificador_categorico.fit_transform(datos.col_categorica)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['elefante', 'gato', 'perro', 'ratón'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codificador_categorico.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digamos que no tiene sentido decir que la media de `elefante` y `perro` no es `gato`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Para estos casos una técnica que se puede usar se llama `one-hot encoding`. Lo que significa es que creamos n columnas binarias, con el valor 0 por defecto salvo la columna referente a la observación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esto podemos usar \n",
    "[OneHotEncoder](scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_codificador = preprocessing.OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.col_categorica.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=['ratón' 'elefante' 'ratón' 'gato' 'gato' 'perro' 'perro' 'perro'\n 'elefante' 'elefante' 'perro' 'elefante' 'gato' 'ratón' 'gato' 'ratón'\n 'elefante' 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'ratón' 'gato'\n 'gato' 'ratón' 'gato' 'elefante' 'gato' 'elefante' 'elefante' 'elefante'\n 'elefante' 'ratón' 'elefante' 'gato' 'elefante' 'gato' 'gato' 'gato'\n 'gato' 'ratón' 'elefante' 'gato' 'gato' 'perro' 'elefante' 'gato'\n 'elefante' 'perro' 'ratón' 'perro' 'elefante' 'ratón' 'ratón' 'gato'\n 'gato' 'elefante' 'ratón' 'perro' 'gato' 'gato' 'gato' 'gato' 'ratón'\n 'elefante' 'elefante' 'perro' 'gato' 'ratón' 'perro' 'elefante' 'gato'\n 'gato' 'ratón' 'ratón' 'elefante' 'perro' 'ratón' 'ratón' 'elefante'\n 'gato' 'perro' 'ratón' 'gato' 'elefante' 'elefante' 'perro' 'perro'\n 'perro' 'ratón' 'gato' 'ratón' 'gato' 'gato' 'elefante' 'gato' 'gato'\n 'perro' 'perro' 'ratón' 'perro' 'gato' 'elefante' 'ratón' 'perro' 'gato'\n 'gato' 'ratón' 'gato' 'perro' 'perro' 'perro' 'gato' 'perro' 'perro'\n 'elefante' 'perro' 'ratón' 'gato' 'gato' 'gato' 'gato' 'ratón' 'ratón'\n 'ratón' 'perro' 'elefante' 'elefante' 'perro' 'ratón' 'gato' 'elefante'\n 'gato' 'ratón' 'ratón' 'elefante' 'gato' 'perro' 'ratón' 'gato'\n 'elefante' 'elefante' 'elefante' 'elefante' 'perro' 'elefante' 'elefante'\n 'gato' 'ratón' 'perro' 'perro' 'gato' 'perro' 'perro' 'elefante' 'gato'\n 'perro' 'perro' 'perro' 'perro' 'gato' 'ratón' 'gato' 'gato' 'gato'\n 'perro' 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'elefante' 'elefante'\n 'ratón' 'elefante' 'elefante' 'elefante' 'ratón' 'ratón' 'gato' 'perro'\n 'elefante' 'elefante' 'gato' 'gato' 'perro' 'elefante' 'elefante'\n 'elefante' 'ratón' 'perro' 'perro' 'gato' 'ratón' 'gato' 'perro' 'ratón'\n 'elefante' 'ratón' 'ratón' 'gato' 'ratón' 'gato' 'ratón' 'elefante'\n 'gato' 'gato' 'perro' 'elefante' 'perro' 'perro' 'gato' 'elefante'\n 'elefante' 'elefante' 'gato' 'perro' 'gato' 'perro' 'elefante' 'elefante'\n 'elefante' 'elefante' 'perro' 'gato' 'gato' 'elefante' 'ratón' 'perro'\n 'perro' 'ratón' 'ratón' 'perro' 'perro' 'elefante' 'elefante' 'perro'\n 'gato' 'perro' 'ratón' 'perro' 'ratón' 'gato' 'ratón' 'perro' 'elefante'\n 'gato' 'gato' 'ratón' 'ratón' 'perro' 'gato' 'ratón' 'ratón' 'perro'\n 'elefante' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'elefante' 'perro'\n 'ratón' 'perro' 'perro' 'perro' 'ratón' 'ratón' 'ratón' 'perro'\n 'elefante' 'perro' 'elefante' 'gato' 'elefante' 'elefante' 'elefante'\n 'elefante' 'ratón' 'elefante' 'ratón' 'elefante' 'perro' 'ratón' 'gato'\n 'elefante' 'perro' 'perro' 'ratón' 'perro' 'ratón' 'gato' 'gato' 'perro'\n 'gato' 'ratón' 'perro' 'elefante' 'gato' 'perro' 'gato' 'elefante'\n 'perro' 'ratón' 'gato' 'perro' 'elefante' 'elefante' 'gato' 'ratón'\n 'gato' 'elefante' 'perro' 'perro' 'ratón' 'gato' 'ratón' 'gato' 'perro'\n 'gato' 'perro' 'ratón' 'ratón' 'perro' 'ratón' 'gato' 'gato' 'ratón'\n 'ratón' 'gato' 'perro' 'elefante' 'elefante' 'gato' 'ratón' 'gato'\n 'ratón' 'gato' 'ratón' 'elefante' 'ratón' 'ratón' 'elefante' 'elefante'\n 'gato' 'elefante' 'ratón' 'elefante' 'perro' 'elefante' 'elefante'\n 'perro' 'gato' 'gato' 'elefante' 'perro' 'perro' 'perro' 'perro' 'gato'\n 'perro' 'ratón' 'ratón' 'gato' 'elefante' 'gato' 'gato' 'perro' 'ratón'\n 'perro' 'perro' 'elefante' 'ratón' 'ratón' 'gato' 'perro' 'perro'\n 'elefante' 'gato' 'perro' 'gato' 'gato' 'ratón' 'ratón' 'gato' 'perro'\n 'gato' 'ratón' 'perro' 'perro' 'ratón' 'gato' 'perro' 'perro' 'gato'\n 'gato' 'perro' 'elefante' 'ratón' 'ratón' 'perro' 'elefante' 'elefante'\n 'gato' 'ratón' 'elefante' 'perro' 'ratón' 'elefante' 'perro' 'perro'\n 'gato' 'elefante' 'elefante' 'elefante' 'ratón' 'perro' 'gato' 'gato'\n 'ratón' 'ratón' 'ratón' 'perro' 'elefante' 'gato' 'gato' 'gato' 'perro'\n 'elefante' 'gato' 'elefante' 'elefante' 'elefante' 'ratón' 'gato' 'perro'\n 'elefante' 'elefante' 'elefante' 'ratón' 'elefante' 'perro' 'ratón'\n 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'gato' 'ratón' 'perro' 'perro'\n 'ratón' 'gato' 'elefante' 'perro' 'gato' 'gato' 'ratón' 'elefante'\n 'ratón' 'ratón' 'ratón' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'ratón'\n 'ratón' 'perro' 'ratón' 'ratón' 'perro' 'perro' 'gato' 'perro' 'ratón'\n 'perro' 'elefante' 'ratón' 'elefante' 'gato' 'perro' 'gato' 'elefante'\n 'ratón' 'perro' 'perro' 'gato' 'perro' 'gato' 'gato' 'perro' 'gato'\n 'elefante' 'elefante' 'ratón' 'ratón' 'gato' 'gato' 'gato' 'perro'\n 'elefante' 'gato' 'ratón' 'elefante' 'elefante' 'ratón' 'ratón' 'perro'\n 'gato' 'gato' 'elefante' 'elefante' 'ratón' 'elefante' 'gato' 'ratón'\n 'gato' 'gato' 'ratón' 'perro' 'ratón' 'elefante' 'ratón' 'elefante'\n 'gato' 'gato' 'gato' 'gato' 'perro' 'gato' 'gato' 'ratón' 'perro'\n 'elefante' 'gato' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'ratón'\n 'elefante' 'ratón' 'perro' 'gato' 'perro' 'perro' 'perro' 'perro' 'gato'\n 'ratón' 'gato' 'elefante' 'perro' 'gato' 'perro' 'ratón' 'ratón' 'perro'\n 'elefante' 'elefante' 'elefante' 'perro' 'perro' 'ratón' 'perro' 'perro'\n 'ratón' 'ratón' 'ratón' 'gato' 'perro' 'gato' 'gato' 'ratón' 'ratón'\n 'gato' 'perro' 'gato' 'ratón' 'perro' 'perro' 'perro' 'ratón' 'ratón'\n 'ratón' 'elefante' 'gato' 'gato' 'elefante' 'gato' 'gato' 'ratón' 'ratón'\n 'ratón' 'perro' 'perro' 'elefante' 'elefante' 'elefante' 'elefante'\n 'elefante' 'perro' 'ratón' 'ratón' 'ratón' 'gato' 'ratón' 'gato' 'gato'\n 'elefante' 'elefante' 'elefante' 'perro' 'ratón' 'perro' 'perro' 'perro'\n 'gato' 'ratón' 'elefante' 'perro' 'elefante' 'elefante' 'elefante'\n 'elefante' 'elefante' 'perro' 'elefante' 'perro' 'ratón' 'elefante'\n 'elefante' 'perro' 'gato' 'ratón' 'ratón' 'elefante' 'elefante' 'gato'\n 'ratón' 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'perro' 'perro'\n 'perro' 'elefante' 'elefante' 'elefante' 'gato' 'ratón' 'elefante'\n 'ratón' 'gato' 'perro' 'gato' 'elefante' 'gato' 'ratón' 'gato' 'gato'\n 'elefante' 'gato' 'gato' 'elefante' 'perro' 'perro' 'gato' 'perro' 'gato'\n 'ratón' 'gato' 'ratón' 'perro' 'perro' 'ratón' 'elefante' 'perro' 'perro'\n 'gato' 'perro' 'gato' 'perro' 'elefante' 'ratón' 'elefante' 'perro'\n 'perro' 'gato' 'perro' 'perro' 'gato' 'ratón' 'gato' 'gato' 'elefante'\n 'gato' 'perro' 'gato' 'gato' 'perro' 'gato' 'ratón' 'ratón' 'perro'\n 'gato' 'gato' 'elefante' 'ratón' 'perro' 'elefante' 'elefante' 'ratón'\n 'ratón' 'perro' 'gato' 'perro' 'ratón' 'gato' 'gato' 'perro' 'perro'\n 'perro' 'gato' 'perro' 'elefante' 'elefante' 'perro' 'perro' 'elefante'\n 'ratón' 'gato' 'ratón' 'gato' 'elefante' 'elefante' 'perro' 'ratón'\n 'gato' 'elefante' 'perro' 'perro' 'gato' 'gato' 'ratón' 'perro' 'perro'\n 'ratón' 'perro' 'ratón' 'gato' 'perro' 'elefante' 'ratón' 'ratón' 'perro'\n 'gato' 'perro' 'perro' 'perro' 'elefante' 'perro' 'gato' 'ratón' 'ratón'\n 'perro' 'ratón' 'gato' 'gato' 'ratón' 'perro' 'ratón' 'ratón' 'perro'\n 'elefante' 'gato' 'ratón' 'elefante' 'elefante' 'perro' 'gato' 'perro'\n 'perro' 'gato' 'ratón' 'perro' 'ratón' 'gato' 'ratón' 'elefante'\n 'elefante' 'perro' 'elefante' 'perro' 'gato' 'ratón' 'gato' 'perro'\n 'elefante' 'elefante' 'ratón' 'elefante' 'ratón' 'elefante' 'elefante'\n 'ratón' 'perro' 'perro' 'perro' 'elefante' 'ratón' 'gato' 'gato' 'gato'\n 'perro' 'elefante' 'elefante' 'elefante' 'gato' 'elefante' 'perro' 'gato'\n 'elefante' 'elefante' 'ratón' 'gato' 'gato' 'ratón' 'perro' 'elefante'\n 'perro' 'perro' 'perro' 'elefante' 'perro' 'perro' 'elefante' 'perro'\n 'elefante' 'gato' 'elefante' 'gato' 'gato' 'perro' 'gato' 'ratón'\n 'elefante' 'perro' 'perro' 'perro' 'elefante' 'perro' 'ratón' 'gato'\n 'elefante' 'gato' 'ratón' 'gato' 'gato' 'ratón' 'elefante' 'gato'\n 'elefante' 'elefante' 'gato' 'perro' 'gato' 'elefante' 'perro' 'ratón'\n 'elefante' 'elefante' 'elefante' 'elefante' 'perro' 'ratón' 'perro'\n 'ratón' 'gato' 'elefante' 'ratón' 'ratón' 'perro' 'elefante' 'ratón'\n 'ratón' 'perro' 'gato' 'elefante' 'ratón' 'ratón' 'gato' 'gato'\n 'elefante' 'perro' 'elefante' 'perro' 'gato' 'perro' 'perro' 'perro'\n 'perro' 'ratón' 'ratón' 'gato' 'perro' 'gato' 'elefante' 'perro' 'ratón'\n 'perro' 'ratón' 'perro' 'gato' 'elefante' 'ratón' 'gato' 'perro' 'ratón'\n 'perro' 'elefante' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'ratón'\n 'ratón' 'perro' 'gato' 'gato' 'gato' 'perro' 'ratón' 'perro' 'ratón'\n 'elefante' 'perro' 'perro' 'ratón' 'elefante' 'ratón' 'elefante' 'ratón'\n 'gato' 'gato' 'gato' 'perro' 'elefante' 'gato' 'perro' 'gato' 'ratón'\n 'ratón' 'gato' 'elefante' 'gato' 'elefante' 'elefante' 'gato' 'ratón'\n 'ratón' 'ratón' 'gato' 'elefante' 'perro' 'perro' 'elefante' 'ratón'\n 'perro' 'elefante' 'ratón' 'gato' 'perro' 'ratón' 'gato' 'gato' 'ratón'\n 'ratón' 'gato' 'perro' 'perro' 'perro' 'elefante' 'gato' 'ratón' 'ratón'\n 'elefante' 'ratón' 'elefante' 'elefante' 'elefante'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moh_codificador\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol_categorica\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/data/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:818\u001b[0m, in \u001b[0;36mOneHotEncoder.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;124;03mFit OneHotEncoder to X.\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;124;03m    Fitted encoder.\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_keywords()\n\u001b[0;32m--> 818\u001b[0m fit_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infrequent_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infrequent_enabled:\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_infrequent_category_mapping(\n\u001b[1;32m    826\u001b[0m         fit_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m], fit_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory_counts\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    827\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/data/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:80\u001b[0m, in \u001b[0;36m_BaseEncoder._fit\u001b[0;34m(self, X, handle_unknown, force_all_finite, return_counts)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 80\u001b[0m X_list, n_samples, n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m n_features\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/data/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:45\u001b[0m, in \u001b[0;36m_BaseEncoder._check_X\u001b[0;34m(self, X, force_all_finite)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mPerform custom check_array:\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m- convert list of strings to object dtype\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# if not a dataframe, do normal check_array validation\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     X_temp \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(X_temp\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mstr_):\n\u001b[1;32m     47\u001b[0m         X \u001b[38;5;241m=\u001b[39m check_array(X, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m, force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite)\n",
      "File \u001b[0;32m~/anaconda3/envs/data/lib/python3.10/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 879\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    880\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    881\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    884\u001b[0m         )\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    890\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=['ratón' 'elefante' 'ratón' 'gato' 'gato' 'perro' 'perro' 'perro'\n 'elefante' 'elefante' 'perro' 'elefante' 'gato' 'ratón' 'gato' 'ratón'\n 'elefante' 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'ratón' 'gato'\n 'gato' 'ratón' 'gato' 'elefante' 'gato' 'elefante' 'elefante' 'elefante'\n 'elefante' 'ratón' 'elefante' 'gato' 'elefante' 'gato' 'gato' 'gato'\n 'gato' 'ratón' 'elefante' 'gato' 'gato' 'perro' 'elefante' 'gato'\n 'elefante' 'perro' 'ratón' 'perro' 'elefante' 'ratón' 'ratón' 'gato'\n 'gato' 'elefante' 'ratón' 'perro' 'gato' 'gato' 'gato' 'gato' 'ratón'\n 'elefante' 'elefante' 'perro' 'gato' 'ratón' 'perro' 'elefante' 'gato'\n 'gato' 'ratón' 'ratón' 'elefante' 'perro' 'ratón' 'ratón' 'elefante'\n 'gato' 'perro' 'ratón' 'gato' 'elefante' 'elefante' 'perro' 'perro'\n 'perro' 'ratón' 'gato' 'ratón' 'gato' 'gato' 'elefante' 'gato' 'gato'\n 'perro' 'perro' 'ratón' 'perro' 'gato' 'elefante' 'ratón' 'perro' 'gato'\n 'gato' 'ratón' 'gato' 'perro' 'perro' 'perro' 'gato' 'perro' 'perro'\n 'elefante' 'perro' 'ratón' 'gato' 'gato' 'gato' 'gato' 'ratón' 'ratón'\n 'ratón' 'perro' 'elefante' 'elefante' 'perro' 'ratón' 'gato' 'elefante'\n 'gato' 'ratón' 'ratón' 'elefante' 'gato' 'perro' 'ratón' 'gato'\n 'elefante' 'elefante' 'elefante' 'elefante' 'perro' 'elefante' 'elefante'\n 'gato' 'ratón' 'perro' 'perro' 'gato' 'perro' 'perro' 'elefante' 'gato'\n 'perro' 'perro' 'perro' 'perro' 'gato' 'ratón' 'gato' 'gato' 'gato'\n 'perro' 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'elefante' 'elefante'\n 'ratón' 'elefante' 'elefante' 'elefante' 'ratón' 'ratón' 'gato' 'perro'\n 'elefante' 'elefante' 'gato' 'gato' 'perro' 'elefante' 'elefante'\n 'elefante' 'ratón' 'perro' 'perro' 'gato' 'ratón' 'gato' 'perro' 'ratón'\n 'elefante' 'ratón' 'ratón' 'gato' 'ratón' 'gato' 'ratón' 'elefante'\n 'gato' 'gato' 'perro' 'elefante' 'perro' 'perro' 'gato' 'elefante'\n 'elefante' 'elefante' 'gato' 'perro' 'gato' 'perro' 'elefante' 'elefante'\n 'elefante' 'elefante' 'perro' 'gato' 'gato' 'elefante' 'ratón' 'perro'\n 'perro' 'ratón' 'ratón' 'perro' 'perro' 'elefante' 'elefante' 'perro'\n 'gato' 'perro' 'ratón' 'perro' 'ratón' 'gato' 'ratón' 'perro' 'elefante'\n 'gato' 'gato' 'ratón' 'ratón' 'perro' 'gato' 'ratón' 'ratón' 'perro'\n 'elefante' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'elefante' 'perro'\n 'ratón' 'perro' 'perro' 'perro' 'ratón' 'ratón' 'ratón' 'perro'\n 'elefante' 'perro' 'elefante' 'gato' 'elefante' 'elefante' 'elefante'\n 'elefante' 'ratón' 'elefante' 'ratón' 'elefante' 'perro' 'ratón' 'gato'\n 'elefante' 'perro' 'perro' 'ratón' 'perro' 'ratón' 'gato' 'gato' 'perro'\n 'gato' 'ratón' 'perro' 'elefante' 'gato' 'perro' 'gato' 'elefante'\n 'perro' 'ratón' 'gato' 'perro' 'elefante' 'elefante' 'gato' 'ratón'\n 'gato' 'elefante' 'perro' 'perro' 'ratón' 'gato' 'ratón' 'gato' 'perro'\n 'gato' 'perro' 'ratón' 'ratón' 'perro' 'ratón' 'gato' 'gato' 'ratón'\n 'ratón' 'gato' 'perro' 'elefante' 'elefante' 'gato' 'ratón' 'gato'\n 'ratón' 'gato' 'ratón' 'elefante' 'ratón' 'ratón' 'elefante' 'elefante'\n 'gato' 'elefante' 'ratón' 'elefante' 'perro' 'elefante' 'elefante'\n 'perro' 'gato' 'gato' 'elefante' 'perro' 'perro' 'perro' 'perro' 'gato'\n 'perro' 'ratón' 'ratón' 'gato' 'elefante' 'gato' 'gato' 'perro' 'ratón'\n 'perro' 'perro' 'elefante' 'ratón' 'ratón' 'gato' 'perro' 'perro'\n 'elefante' 'gato' 'perro' 'gato' 'gato' 'ratón' 'ratón' 'gato' 'perro'\n 'gato' 'ratón' 'perro' 'perro' 'ratón' 'gato' 'perro' 'perro' 'gato'\n 'gato' 'perro' 'elefante' 'ratón' 'ratón' 'perro' 'elefante' 'elefante'\n 'gato' 'ratón' 'elefante' 'perro' 'ratón' 'elefante' 'perro' 'perro'\n 'gato' 'elefante' 'elefante' 'elefante' 'ratón' 'perro' 'gato' 'gato'\n 'ratón' 'ratón' 'ratón' 'perro' 'elefante' 'gato' 'gato' 'gato' 'perro'\n 'elefante' 'gato' 'elefante' 'elefante' 'elefante' 'ratón' 'gato' 'perro'\n 'elefante' 'elefante' 'elefante' 'ratón' 'elefante' 'perro' 'ratón'\n 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'gato' 'ratón' 'perro' 'perro'\n 'ratón' 'gato' 'elefante' 'perro' 'gato' 'gato' 'ratón' 'elefante'\n 'ratón' 'ratón' 'ratón' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'ratón'\n 'ratón' 'perro' 'ratón' 'ratón' 'perro' 'perro' 'gato' 'perro' 'ratón'\n 'perro' 'elefante' 'ratón' 'elefante' 'gato' 'perro' 'gato' 'elefante'\n 'ratón' 'perro' 'perro' 'gato' 'perro' 'gato' 'gato' 'perro' 'gato'\n 'elefante' 'elefante' 'ratón' 'ratón' 'gato' 'gato' 'gato' 'perro'\n 'elefante' 'gato' 'ratón' 'elefante' 'elefante' 'ratón' 'ratón' 'perro'\n 'gato' 'gato' 'elefante' 'elefante' 'ratón' 'elefante' 'gato' 'ratón'\n 'gato' 'gato' 'ratón' 'perro' 'ratón' 'elefante' 'ratón' 'elefante'\n 'gato' 'gato' 'gato' 'gato' 'perro' 'gato' 'gato' 'ratón' 'perro'\n 'elefante' 'gato' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'ratón'\n 'elefante' 'ratón' 'perro' 'gato' 'perro' 'perro' 'perro' 'perro' 'gato'\n 'ratón' 'gato' 'elefante' 'perro' 'gato' 'perro' 'ratón' 'ratón' 'perro'\n 'elefante' 'elefante' 'elefante' 'perro' 'perro' 'ratón' 'perro' 'perro'\n 'ratón' 'ratón' 'ratón' 'gato' 'perro' 'gato' 'gato' 'ratón' 'ratón'\n 'gato' 'perro' 'gato' 'ratón' 'perro' 'perro' 'perro' 'ratón' 'ratón'\n 'ratón' 'elefante' 'gato' 'gato' 'elefante' 'gato' 'gato' 'ratón' 'ratón'\n 'ratón' 'perro' 'perro' 'elefante' 'elefante' 'elefante' 'elefante'\n 'elefante' 'perro' 'ratón' 'ratón' 'ratón' 'gato' 'ratón' 'gato' 'gato'\n 'elefante' 'elefante' 'elefante' 'perro' 'ratón' 'perro' 'perro' 'perro'\n 'gato' 'ratón' 'elefante' 'perro' 'elefante' 'elefante' 'elefante'\n 'elefante' 'elefante' 'perro' 'elefante' 'perro' 'ratón' 'elefante'\n 'elefante' 'perro' 'gato' 'ratón' 'ratón' 'elefante' 'elefante' 'gato'\n 'ratón' 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'perro' 'perro'\n 'perro' 'elefante' 'elefante' 'elefante' 'gato' 'ratón' 'elefante'\n 'ratón' 'gato' 'perro' 'gato' 'elefante' 'gato' 'ratón' 'gato' 'gato'\n 'elefante' 'gato' 'gato' 'elefante' 'perro' 'perro' 'gato' 'perro' 'gato'\n 'ratón' 'gato' 'ratón' 'perro' 'perro' 'ratón' 'elefante' 'perro' 'perro'\n 'gato' 'perro' 'gato' 'perro' 'elefante' 'ratón' 'elefante' 'perro'\n 'perro' 'gato' 'perro' 'perro' 'gato' 'ratón' 'gato' 'gato' 'elefante'\n 'gato' 'perro' 'gato' 'gato' 'perro' 'gato' 'ratón' 'ratón' 'perro'\n 'gato' 'gato' 'elefante' 'ratón' 'perro' 'elefante' 'elefante' 'ratón'\n 'ratón' 'perro' 'gato' 'perro' 'ratón' 'gato' 'gato' 'perro' 'perro'\n 'perro' 'gato' 'perro' 'elefante' 'elefante' 'perro' 'perro' 'elefante'\n 'ratón' 'gato' 'ratón' 'gato' 'elefante' 'elefante' 'perro' 'ratón'\n 'gato' 'elefante' 'perro' 'perro' 'gato' 'gato' 'ratón' 'perro' 'perro'\n 'ratón' 'perro' 'ratón' 'gato' 'perro' 'elefante' 'ratón' 'ratón' 'perro'\n 'gato' 'perro' 'perro' 'perro' 'elefante' 'perro' 'gato' 'ratón' 'ratón'\n 'perro' 'ratón' 'gato' 'gato' 'ratón' 'perro' 'ratón' 'ratón' 'perro'\n 'elefante' 'gato' 'ratón' 'elefante' 'elefante' 'perro' 'gato' 'perro'\n 'perro' 'gato' 'ratón' 'perro' 'ratón' 'gato' 'ratón' 'elefante'\n 'elefante' 'perro' 'elefante' 'perro' 'gato' 'ratón' 'gato' 'perro'\n 'elefante' 'elefante' 'ratón' 'elefante' 'ratón' 'elefante' 'elefante'\n 'ratón' 'perro' 'perro' 'perro' 'elefante' 'ratón' 'gato' 'gato' 'gato'\n 'perro' 'elefante' 'elefante' 'elefante' 'gato' 'elefante' 'perro' 'gato'\n 'elefante' 'elefante' 'ratón' 'gato' 'gato' 'ratón' 'perro' 'elefante'\n 'perro' 'perro' 'perro' 'elefante' 'perro' 'perro' 'elefante' 'perro'\n 'elefante' 'gato' 'elefante' 'gato' 'gato' 'perro' 'gato' 'ratón'\n 'elefante' 'perro' 'perro' 'perro' 'elefante' 'perro' 'ratón' 'gato'\n 'elefante' 'gato' 'ratón' 'gato' 'gato' 'ratón' 'elefante' 'gato'\n 'elefante' 'elefante' 'gato' 'perro' 'gato' 'elefante' 'perro' 'ratón'\n 'elefante' 'elefante' 'elefante' 'elefante' 'perro' 'ratón' 'perro'\n 'ratón' 'gato' 'elefante' 'ratón' 'ratón' 'perro' 'elefante' 'ratón'\n 'ratón' 'perro' 'gato' 'elefante' 'ratón' 'ratón' 'gato' 'gato'\n 'elefante' 'perro' 'elefante' 'perro' 'gato' 'perro' 'perro' 'perro'\n 'perro' 'ratón' 'ratón' 'gato' 'perro' 'gato' 'elefante' 'perro' 'ratón'\n 'perro' 'ratón' 'perro' 'gato' 'elefante' 'ratón' 'gato' 'perro' 'ratón'\n 'perro' 'elefante' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'ratón'\n 'ratón' 'perro' 'gato' 'gato' 'gato' 'perro' 'ratón' 'perro' 'ratón'\n 'elefante' 'perro' 'perro' 'ratón' 'elefante' 'ratón' 'elefante' 'ratón'\n 'gato' 'gato' 'gato' 'perro' 'elefante' 'gato' 'perro' 'gato' 'ratón'\n 'ratón' 'gato' 'elefante' 'gato' 'elefante' 'elefante' 'gato' 'ratón'\n 'ratón' 'ratón' 'gato' 'elefante' 'perro' 'perro' 'elefante' 'ratón'\n 'perro' 'elefante' 'ratón' 'gato' 'perro' 'ratón' 'gato' 'gato' 'ratón'\n 'ratón' 'gato' 'perro' 'perro' 'perro' 'elefante' 'gato' 'ratón' 'ratón'\n 'elefante' 'ratón' 'elefante' 'elefante' 'elefante'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "oh_codificador.fit(datos.col_categorica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que OneHotEncoder falla cuando se le pasan strings en vez de numeros. Por ello primero tenemos que convertir las variables categóricas a numéricas usando LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorias_codificadas = label_codificador_categorico.transform(datos.col_categorica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 3, 1, 1, 2, 2, 2, 0, 0, 2, 0, 1, 3, 1, 3, 0, 3, 3, 0, 3, 3,\n",
       "       3, 1, 1, 3, 1, 0, 1, 0, 0, 0, 0, 3, 0, 1, 0, 1, 1, 1, 1, 3, 0, 1,\n",
       "       1, 2, 0, 1, 0, 2, 3, 2, 0, 3, 3, 1, 1, 0, 3, 2, 1, 1, 1, 1, 3, 0,\n",
       "       0, 2, 1, 3, 2, 0, 1, 1, 3, 3, 0, 2, 3, 3, 0, 1, 2, 3, 1, 0, 0, 2,\n",
       "       2, 2, 3, 1, 3, 1, 1, 0, 1, 1, 2, 2, 3, 2, 1, 0, 3, 2, 1, 1, 3, 1,\n",
       "       2, 2, 2, 1, 2, 2, 0, 2, 3, 1, 1, 1, 1, 3, 3, 3, 2, 0, 0, 2, 3, 1,\n",
       "       0, 1, 3, 3, 0, 1, 2, 3, 1, 0, 0, 0, 0, 2, 0, 0, 1, 3, 2, 2, 1, 2,\n",
       "       2, 0, 1, 2, 2, 2, 2, 1, 3, 1, 1, 1, 2, 3, 3, 0, 3, 3, 0, 0, 3, 0,\n",
       "       0, 0, 3, 3, 1, 2, 0, 0, 1, 1, 2, 0, 0, 0, 3, 2, 2, 1, 3, 1, 2, 3,\n",
       "       0, 3, 3, 1, 3, 1, 3, 0, 1, 1, 2, 0, 2, 2, 1, 0, 0, 0, 1, 2, 1, 2,\n",
       "       0, 0, 0, 0, 2, 1, 1, 0, 3, 2, 2, 3, 3, 2, 2, 0, 0, 2, 1, 2, 3, 2,\n",
       "       3, 1, 3, 2, 0, 1, 1, 3, 3, 2, 1, 3, 3, 2, 0, 1, 3, 2, 0, 3, 0, 2,\n",
       "       3, 2, 2, 2, 3, 3, 3, 2, 0, 2, 0, 1, 0, 0, 0, 0, 3, 0, 3, 0, 2, 3,\n",
       "       1, 0, 2, 2, 3, 2, 3, 1, 1, 2, 1, 3, 2, 0, 1, 2, 1, 0, 2, 3, 1, 2,\n",
       "       0, 0, 1, 3, 1, 0, 2, 2, 3, 1, 3, 1, 2, 1, 2, 3, 3, 2, 3, 1, 1, 3,\n",
       "       3, 1, 2, 0, 0, 1, 3, 1, 3, 1, 3, 0, 3, 3, 0, 0, 1, 0, 3, 0, 2, 0,\n",
       "       0, 2, 1, 1, 0, 2, 2, 2, 2, 1, 2, 3, 3, 1, 0, 1, 1, 2, 3, 2, 2, 0,\n",
       "       3, 3, 1, 2, 2, 0, 1, 2, 1, 1, 3, 3, 1, 2, 1, 3, 2, 2, 3, 1, 2, 2,\n",
       "       1, 1, 2, 0, 3, 3, 2, 0, 0, 1, 3, 0, 2, 3, 0, 2, 2, 1, 0, 0, 0, 3,\n",
       "       2, 1, 1, 3, 3, 3, 2, 0, 1, 1, 1, 2, 0, 1, 0, 0, 0, 3, 1, 2, 0, 0,\n",
       "       0, 3, 0, 2, 3, 3, 3, 0, 3, 3, 1, 3, 2, 2, 3, 1, 0, 2, 1, 1, 3, 0,\n",
       "       3, 3, 3, 1, 3, 2, 0, 3, 3, 3, 2, 3, 3, 2, 2, 1, 2, 3, 2, 0, 3, 0,\n",
       "       1, 2, 1, 0, 3, 2, 2, 1, 2, 1, 1, 2, 1, 0, 0, 3, 3, 1, 1, 1, 2, 0,\n",
       "       1, 3, 0, 0, 3, 3, 2, 1, 1, 0, 0, 3, 0, 1, 3, 1, 1, 3, 2, 3, 0, 3,\n",
       "       0, 1, 1, 1, 1, 2, 1, 1, 3, 2, 0, 1, 1, 3, 2, 0, 3, 3, 0, 3, 2, 1,\n",
       "       2, 2, 2, 2, 1, 3, 1, 0, 2, 1, 2, 3, 3, 2, 0, 0, 0, 2, 2, 3, 2, 2,\n",
       "       3, 3, 3, 1, 2, 1, 1, 3, 3, 1, 2, 1, 3, 2, 2, 2, 3, 3, 3, 0, 1, 1,\n",
       "       0, 1, 1, 3, 3, 3, 2, 2, 0, 0, 0, 0, 0, 2, 3, 3, 3, 1, 3, 1, 1, 0,\n",
       "       0, 0, 2, 3, 2, 2, 2, 1, 3, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 3, 0, 0,\n",
       "       2, 1, 3, 3, 0, 0, 1, 3, 3, 3, 0, 3, 3, 2, 2, 2, 0, 0, 0, 1, 3, 0,\n",
       "       3, 1, 2, 1, 0, 1, 3, 1, 1, 0, 1, 1, 0, 2, 2, 1, 2, 1, 3, 1, 3, 2,\n",
       "       2, 3, 0, 2, 2, 1, 2, 1, 2, 0, 3, 0, 2, 2, 1, 2, 2, 1, 3, 1, 1, 0,\n",
       "       1, 2, 1, 1, 2, 1, 3, 3, 2, 1, 1, 0, 3, 2, 0, 0, 3, 3, 2, 1, 2, 3,\n",
       "       1, 1, 2, 2, 2, 1, 2, 0, 0, 2, 2, 0, 3, 1, 3, 1, 0, 0, 2, 3, 1, 0,\n",
       "       2, 2, 1, 1, 3, 2, 2, 3, 2, 3, 1, 2, 0, 3, 3, 2, 1, 2, 2, 2, 0, 2,\n",
       "       1, 3, 3, 2, 3, 1, 1, 3, 2, 3, 3, 2, 0, 1, 3, 0, 0, 2, 1, 2, 2, 1,\n",
       "       3, 2, 3, 1, 3, 0, 0, 2, 0, 2, 1, 3, 1, 2, 0, 0, 3, 0, 3, 0, 0, 3,\n",
       "       2, 2, 2, 0, 3, 1, 1, 1, 2, 0, 0, 0, 1, 0, 2, 1, 0, 0, 3, 1, 1, 3,\n",
       "       2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 0, 1, 0, 1, 1, 2, 1, 3, 0, 2, 2, 2,\n",
       "       0, 2, 3, 1, 0, 1, 3, 1, 1, 3, 0, 1, 0, 0, 1, 2, 1, 0, 2, 3, 0, 0,\n",
       "       0, 0, 2, 3, 2, 3, 1, 0, 3, 3, 2, 0, 3, 3, 2, 1, 0, 3, 3, 1, 1, 0,\n",
       "       2, 0, 2, 1, 2, 2, 2, 2, 3, 3, 1, 2, 1, 0, 2, 3, 2, 3, 2, 1, 0, 3,\n",
       "       1, 2, 3, 2, 0, 1, 3, 2, 0, 3, 3, 3, 2, 1, 1, 1, 2, 3, 2, 3, 0, 2,\n",
       "       2, 3, 0, 3, 0, 3, 1, 1, 1, 2, 0, 1, 2, 1, 3, 3, 1, 0, 1, 0, 0, 1,\n",
       "       3, 3, 3, 1, 0, 2, 2, 0, 3, 2, 0, 3, 1, 2, 3, 1, 1, 3, 3, 1, 2, 2,\n",
       "       2, 0, 1, 3, 3, 0, 3, 0, 0, 0])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorias_codificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorias_codificadas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x4 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorias_oh_codificadas = oh_codificador.fit_transform(categorias_codificadas.reshape(1000,1))\n",
    "categorias_oh_codificadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que por defecto `OneHotEncoder` no devuelve un numpy array, sino una matriz `sparse`. La traducción sería \"matriz escasa\", y es una manera de representar matrices con muchos ceros (como es el caso de OneHot encoding) para consumir poca memoria.\n",
    "\n",
    "Podemos convertir dichas matrices a arrays facilmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorias_oh_codificadas.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos ahora la comparación en memoria de una matriz sparse versus su correspondiente np.array usando la función `sys.getsizeof` que devuelve el uso de memoria un objeto de python en bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(categorias_oh_codificadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32128"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(categorias_oh_codificadas.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos que el encoder devuelva arrays no tenemos más que pasarle el parametro `sparse=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh_codificador = preprocessing.OneHotEncoder(sparse=False)\n",
    "\n",
    "categorias_oh_codificadas = oh_codificador.fit_transform(categorias_codificadas.reshape(1000,1))\n",
    "categorias_oh_codificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OneHotEncoder' object has no attribute 'feature_indices_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moh_codificador\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_indices_\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OneHotEncoder' object has no attribute 'feature_indices_'"
     ]
    }
   ],
   "source": [
    "oh_codificador.feature_indices_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas tiene la funcion auxiliar `get_dummies` que hace esto automáticamente de forma más fácil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elefante</th>\n",
       "      <th>gato</th>\n",
       "      <th>perro</th>\n",
       "      <th>ratón</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   elefante   gato  perro  ratón\n",
       "0     False  False  False   True\n",
       "1      True  False  False  False\n",
       "2     False  False  False   True\n",
       "3     False   True  False  False\n",
       "4     False   True  False  False"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(datos.col_categorica).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tenía en su casa una ama que pasaba de los cuarenta, y una sobrina que no llegaba a los veinte, y un mozo de campo y plaza, que así ensillaba el rocín como tomaba la podadera.',\n",
       "       'El resto della concluían sayo de velarte, calzas de velludo para las fiestas con sus pantuflos de lo mismo, los días de entre semana se honraba con su vellori de lo más fino.',\n",
       "       'El resto della concluían sayo de velarte, calzas de velludo para las fiestas con sus pantuflos de lo mismo, los días de entre semana se honraba con su vellori de lo más fino.',\n",
       "       'Una olla de algo más vaca que carnero, salpicón las más noches, duelos y quebrantos los sábados, lentejas los viernes, algún palomino de añadidura los domingos, consumían las tres partes de su hacienda.',\n",
       "       'Tenía en su casa una ama que pasaba de los cuarenta, y una sobrina que no llegaba a los veinte, y un mozo de campo y plaza, que así ensillaba el rocín como tomaba la podadera.',\n",
       "       'En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua, rocín flaco y galgo corredor.',\n",
       "       'En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua, rocín flaco y galgo corredor.',\n",
       "       'El resto della concluían sayo de velarte, calzas de velludo para las fiestas con sus pantuflos de lo mismo, los días de entre semana se honraba con su vellori de lo más fino.',\n",
       "       'Tenía en su casa una ama que pasaba de los cuarenta, y una sobrina que no llegaba a los veinte, y un mozo de campo y plaza, que así ensillaba el rocín como tomaba la podadera.',\n",
       "       'En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua, rocín flaco y galgo corredor.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.col_texto.values[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para convertir texto en variables numéricas, podemos proceder de igual forma que con las variables categóricas, simplemente separando las palabras antes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello tenemos dos vectorizadores en scikit-learn, que convierten texto en vectores.\n",
    "\n",
    "\n",
    "[CountVectorizer]() devuelve un vector con el valor 0 en todas las palabras que no existen en una frase y con el numero de ocurrencias de las palabras que si existen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer un ejemplo para que se vea bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 15 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ejemplo_frases = ['los coches rojos',\n",
    "          'los aviones son rojos',\n",
    "          'los coches y los aviones son rojos',\n",
    "          'los camiones rojos'\n",
    "                 ]\n",
    "\n",
    "\n",
    "vectorizador_count = feature_extraction.text.CountVectorizer()\n",
    "X = vectorizador_count.fit_transform(ejemplo_frases)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aviones', 'camiones', 'coches', 'los', 'rojos', 'son'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizador_count.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aviones</th>\n",
       "      <th>camiones</th>\n",
       "      <th>coches</th>\n",
       "      <th>los</th>\n",
       "      <th>rojos</th>\n",
       "      <th>son</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aviones  camiones  coches  los  rojos  son\n",
       "0        0         0       1    1      1    0\n",
       "1        1         0       0    1      1    1\n",
       "2        1         0       1    2      1    1\n",
       "3        0         1       0    1      1    0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X.toarray(), columns=vectorizador_count.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tomar simplemente el número de veces que aparece cada palabra tiene un problema, y es que da un mayor peso a aquellas palabras que aparecen muchas veces pero que no aportan ningun valor semántico (por ejemplo, `los`). Una manera más sofisticada de vectorizar un texto es en vez de usar el número de apariciones, usar TF-IDF. TF-IDF se traduce como Frecuencia de Texto - Frecuencia Inversa de Documento, y es una medida que asigna pesos a cada palabra en función de su frecuencia de aparición en todos los documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aviones</th>\n",
       "      <th>camiones</th>\n",
       "      <th>coches</th>\n",
       "      <th>los</th>\n",
       "      <th>rojos</th>\n",
       "      <th>son</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730064</td>\n",
       "      <td>0.483222</td>\n",
       "      <td>0.483222</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.589645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.390280</td>\n",
       "      <td>0.390280</td>\n",
       "      <td>0.589645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.438931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.438931</td>\n",
       "      <td>0.581047</td>\n",
       "      <td>0.290524</td>\n",
       "      <td>0.438931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.419880</td>\n",
       "      <td>0.419880</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    aviones  camiones    coches       los     rojos       son\n",
       "0  0.000000  0.000000  0.730064  0.483222  0.483222  0.000000\n",
       "1  0.589645  0.000000  0.000000  0.390280  0.390280  0.589645\n",
       "2  0.438931  0.000000  0.438931  0.581047  0.290524  0.438931\n",
       "3  0.000000  0.804612  0.000000  0.419880  0.419880  0.000000"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizador_tfidf = feature_extraction.text.TfidfVectorizer()\n",
    "X = vectorizador_tfidf.fit_transform(ejemplo_frases)\n",
    "pd.DataFrame(X.toarray(), columns=vectorizador_tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x134 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 28295 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizador_tfidf = feature_extraction.text.TfidfVectorizer()\n",
    "texto_vectorizado = vectorizador_tfidf.fit_transform(datos.col_texto)\n",
    "texto_vectorizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_vectorizado = texto_vectorizado.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bien', 'mal', 'muy bien', 'muy mal', 'regular'], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codificador.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Poniendolo todo junto **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlostr/anaconda3/envs/data/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "col_numericas =  ['col_inexistente1', 'col2', 'col3', 'col_outliers', 'col_outliers2']\n",
    "col_categorica = ['col_categorica']\n",
    "col_texto = ['col_texto']\n",
    "\n",
    "\n",
    "#Variables numéricas\n",
    "imputador = SimpleImputer(strategy=\"mean\")\n",
    "escalador = preprocessing.StandardScaler()\n",
    "var_numericas_imputadas_escalado_standard = escalador.fit_transform(\n",
    "                                                imputador.fit_transform(datos[col_numericas])\n",
    "                                            )\n",
    "df_numerico_procesado = pd.DataFrame(var_numericas_imputadas_escalado_standard,\n",
    "                                                   columns=col_numericas)\n",
    "\n",
    "\n",
    "# Variable categorica\n",
    "label_codificador_categorico = preprocessing.LabelEncoder()\n",
    "categorias_codificadas = label_codificador_categorico.fit_transform(datos[col_categorica])\n",
    "oh_codificador = preprocessing.OneHotEncoder(sparse=False)\n",
    "categorias_oh_codificadas = oh_codificador.fit_transform(categorias_codificadas.reshape(1000,1))\n",
    "\n",
    "df_categorico_procesado = pd.DataFrame(categorias_oh_codificadas, \n",
    "                                       columns=label_codificador_categorico.classes_)\n",
    "\n",
    "\n",
    "# Texto\n",
    "vectorizador_tfidf = feature_extraction.text.TfidfVectorizer()\n",
    "texto_vectorizado = vectorizador_tfidf.fit_transform(datos.col_texto)\n",
    "df_texto_procesado =  pd.DataFrame(texto_vectorizado.toarray(), columns=vectorizador_tfidf.get_feature_names_out())\n",
    "\n",
    "\n",
    "datos_procesados = pd.concat([\n",
    "    df_numerico_procesado,\n",
    "    df_categorico_procesado,\n",
    "    df_texto_procesado \n",
    "], axis=1)\n",
    "\n",
    "# variable ordinal\n",
    "label_codificador_ordinal = preprocessing.LabelEncoder()\n",
    "datos_procesados['col_ordinal'] = label_codificador_ordinal.fit_transform(datos.col_ordinal) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_inexistente1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col_outliers</th>\n",
       "      <th>col_outliers2</th>\n",
       "      <th>elefante</th>\n",
       "      <th>gato</th>\n",
       "      <th>perro</th>\n",
       "      <th>ratón</th>\n",
       "      <th>acordarme</th>\n",
       "      <th>...</th>\n",
       "      <th>vaca</th>\n",
       "      <th>veinte</th>\n",
       "      <th>velarte</th>\n",
       "      <th>vellori</th>\n",
       "      <th>velludo</th>\n",
       "      <th>verdad</th>\n",
       "      <th>verosímiles</th>\n",
       "      <th>viernes</th>\n",
       "      <th>vivía</th>\n",
       "      <th>col_ordinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.399217</td>\n",
       "      <td>0.082807</td>\n",
       "      <td>0.442819</td>\n",
       "      <td>-0.694600</td>\n",
       "      <td>-0.038365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.653605</td>\n",
       "      <td>0.861333</td>\n",
       "      <td>-0.323390</td>\n",
       "      <td>-0.118466</td>\n",
       "      <td>-0.038278</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.226435</td>\n",
       "      <td>-0.766494</td>\n",
       "      <td>-0.484752</td>\n",
       "      <td>-0.464146</td>\n",
       "      <td>-0.038343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.540803</td>\n",
       "      <td>-1.191145</td>\n",
       "      <td>-0.375028</td>\n",
       "      <td>-1.129901</td>\n",
       "      <td>-0.038405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.194272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.616004</td>\n",
       "      <td>-0.766494</td>\n",
       "      <td>-0.516874</td>\n",
       "      <td>0.777743</td>\n",
       "      <td>-0.037257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.376838</td>\n",
       "      <td>0.365907</td>\n",
       "      <td>0.492254</td>\n",
       "      <td>0.611304</td>\n",
       "      <td>-0.038492</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.352799</td>\n",
       "      <td>-1.615795</td>\n",
       "      <td>0.131503</td>\n",
       "      <td>0.700925</td>\n",
       "      <td>-0.037878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-1.104815</td>\n",
       "      <td>0.118194</td>\n",
       "      <td>-0.420944</td>\n",
       "      <td>0.880166</td>\n",
       "      <td>-0.038197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.489641</td>\n",
       "      <td>1.569084</td>\n",
       "      <td>-0.407745</td>\n",
       "      <td>0.816152</td>\n",
       "      <td>-0.038190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.715245</td>\n",
       "      <td>0.224357</td>\n",
       "      <td>-0.136388</td>\n",
       "      <td>0.726531</td>\n",
       "      <td>-0.038315</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     col_inexistente1      col2      col3  col_outliers  col_outliers2  \\\n",
       "0            0.399217  0.082807  0.442819     -0.694600      -0.038365   \n",
       "1           -0.653605  0.861333 -0.323390     -0.118466      -0.038278   \n",
       "2            1.226435 -0.766494 -0.484752     -0.464146      -0.038343   \n",
       "3           -0.540803 -1.191145 -0.375028     -1.129901      -0.038405   \n",
       "4           -0.616004 -0.766494 -0.516874      0.777743      -0.037257   \n",
       "..                ...       ...       ...           ...            ...   \n",
       "995          1.376838  0.365907  0.492254      0.611304      -0.038492   \n",
       "996         -0.352799 -1.615795  0.131503      0.700925      -0.037878   \n",
       "997         -1.104815  0.118194 -0.420944      0.880166      -0.038197   \n",
       "998          1.489641  1.569084 -0.407745      0.816152      -0.038190   \n",
       "999          1.715245  0.224357 -0.136388      0.726531      -0.038315   \n",
       "\n",
       "     elefante  gato  perro  ratón  acordarme  ...      vaca    veinte  \\\n",
       "0         0.0   0.0    0.0    1.0   0.000000  ...  0.000000  0.204745   \n",
       "1         1.0   0.0    0.0    0.0   0.000000  ...  0.000000  0.000000   \n",
       "2         0.0   0.0    0.0    1.0   0.000000  ...  0.000000  0.000000   \n",
       "3         0.0   1.0    0.0    0.0   0.000000  ...  0.194272  0.000000   \n",
       "4         0.0   1.0    0.0    0.0   0.000000  ...  0.000000  0.204745   \n",
       "..        ...   ...    ...    ...        ...  ...       ...       ...   \n",
       "995       1.0   0.0    0.0    0.0   0.000000  ...  0.000000  0.000000   \n",
       "996       0.0   0.0    0.0    1.0   0.000000  ...  0.000000  0.204745   \n",
       "997       1.0   0.0    0.0    0.0   0.000000  ...  0.000000  0.000000   \n",
       "998       1.0   0.0    0.0    0.0   0.197887  ...  0.000000  0.000000   \n",
       "999       1.0   0.0    0.0    0.0   0.000000  ...  0.000000  0.204745   \n",
       "\n",
       "      velarte   vellori   velludo  verdad  verosímiles   viernes     vivía  \\\n",
       "0    0.000000  0.000000  0.000000     0.0          0.0  0.000000  0.000000   \n",
       "1    0.181842  0.181842  0.181842     0.0          0.0  0.000000  0.000000   \n",
       "2    0.181842  0.181842  0.181842     0.0          0.0  0.000000  0.000000   \n",
       "3    0.000000  0.000000  0.000000     0.0          0.0  0.194272  0.000000   \n",
       "4    0.000000  0.000000  0.000000     0.0          0.0  0.000000  0.000000   \n",
       "..        ...       ...       ...     ...          ...       ...       ...   \n",
       "995  0.000000  0.000000  0.000000     0.0          0.0  0.000000  0.000000   \n",
       "996  0.000000  0.000000  0.000000     0.0          0.0  0.000000  0.000000   \n",
       "997  0.181842  0.181842  0.181842     0.0          0.0  0.000000  0.000000   \n",
       "998  0.000000  0.000000  0.000000     0.0          0.0  0.000000  0.197887   \n",
       "999  0.000000  0.000000  0.000000     0.0          0.0  0.000000  0.000000   \n",
       "\n",
       "     col_ordinal  \n",
       "0              2  \n",
       "1              4  \n",
       "2              3  \n",
       "3              1  \n",
       "4              0  \n",
       "..           ...  \n",
       "995            3  \n",
       "996            2  \n",
       "997            4  \n",
       "998            0  \n",
       "999            4  \n",
       "\n",
       "[1000 rows x 144 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_procesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
